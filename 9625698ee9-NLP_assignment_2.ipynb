{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP assignment 2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM1cVkL_tggF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "\n",
        "#preprocessing\n",
        "from nltk.corpus import stopwords  #stopwords\n",
        "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
        "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
        "\n",
        "# for named entity recognition (NER)\n",
        "from nltk import ne_chunk\n",
        "\n",
        "# vectorizers for creating the document-term-matrix (DTM)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "\n",
        "#stop-words\n",
        "#stop_words=set(nltk.corpus.stopwords.words('english'))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "MPd-KpqevKI-",
        "outputId": "51069ec4-d5a3-4f51-d46f-8f42718e7bea"
      },
      "source": [
        "df = pd.read_csv(\"abcnews-date-text.csv\")\n",
        "df.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030219</td>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030219</td>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030219</td>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20030219</td>\n",
              "      <td>ambitious olsson wins triple jump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20030219</td>\n",
              "      <td>antic delighted with record breaking barca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>20030219</td>\n",
              "      <td>aussie qualifier stosur wastes four memphis match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20030219</td>\n",
              "      <td>aust addresses un security council over iraq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20030219</td>\n",
              "      <td>australia is locked into war timetable opp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date                                      headline_text\n",
              "0      20030219  aba decides against community broadcasting lic...\n",
              "1      20030219     act fire witnesses must be aware of defamation\n",
              "2      20030219     a g calls for infrastructure protection summit\n",
              "3      20030219           air nz staff in aust strike for pay rise\n",
              "4      20030219      air nz strike to affect australian travellers\n",
              "5      20030219                  ambitious olsson wins triple jump\n",
              "6      20030219         antic delighted with record breaking barca\n",
              "7      20030219  aussie qualifier stosur wastes four memphis match\n",
              "8      20030219       aust addresses un security council over iraq\n",
              "9      20030219         australia is locked into war timetable opp"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_LCL3IWvKdh"
      },
      "source": [
        "# drop the publish date.\n",
        "df.drop(['publish_date'],axis=1,inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL7xF2OMvYJ-"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlcSXsuMy9AU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "def text_preprocess(tweet):\n",
        "  tweet = tweet.lower()\n",
        "  tweet = re.sub('(\\r\\n|rt|#|amp)','',tweet)\n",
        "  tweet = re.sub('0+[a-z0-9]*','',tweet)\n",
        "  doc = nlp(tweet)\n",
        "  cleaned_tokens = [token.lemma_ for token in doc if ((token.text not in  nlp.Defaults.stop_words) and (token.text not in string.punctuation) and (token.is_space == False))]\n",
        "  cleaned_tweet = \" \".join(token for token in cleaned_tokens)\n",
        "  return cleaned_tweet"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWJzpkrEySEg",
        "outputId": "6f81024d-d5e0-49b2-eb77-04ecf7df9b95"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm4EPzYKymxr"
      },
      "source": [
        "import string,re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1g1tMbrvYUi"
      },
      "source": [
        "\n",
        "df['headline_cleaned_text'] = df['headline_text'].apply(text_preprocess)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae4gG3EpvjCO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "036aa0c8-3298-427c-a9de-24e2acb7d373"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "      <th>headline_cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "      <td>aba decide community broadcasting licence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "      <td>act fire witness aware defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "      <td>g call infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "      <td>air nz staff aust strike pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "      <td>air nz strike affect australian traveller</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       headline_text                      headline_cleaned_text\n",
              "0  aba decides against community broadcasting lic...  aba decide community broadcasting licence\n",
              "1     act fire witnesses must be aware of defamation          act fire witness aware defamation\n",
              "2     a g calls for infrastructure protection summit    g call infrastructure protection summit\n",
              "3           air nz staff in aust strike for pay rise          air nz staff aust strike pay rise\n",
              "4      air nz strike to affect australian travellers  air nz strike affect australian traveller"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ryjwwkDvq05"
      },
      "source": [
        "df.drop(['headline_text'],axis=1,inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AIoT_Ucvq5K"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "model = CountVectorizer(max_df = 0.95,min_df=2,max_features=1000,ngram_range=(1,2),stop_words='english')\n",
        "model_vect = model.fit_transform(df['headline_cleaned_text'].values)\n",
        "vocab = model.get_feature_names()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXvxR1uqzg_j"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda_model=LatentDirichletAllocation(n_components=5,random_state=42,max_iter=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzcNzYFwzhQL"
      },
      "source": [
        "lda_top=lda_model.fit_transform(model_vect)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR6-XDff0GG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f1cb3d-fb29-45c4-e448-2772b7f176f7"
      },
      "source": [
        "print(lda_top.shape)  # (no_of_doc,no_of_topics)\n",
        "print(lda_top)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426297, 5)\n",
            "[[0.05134032 0.05062912 0.79659887 0.05107629 0.05035539]\n",
            " [0.06778517 0.06692448 0.06789909 0.73052434 0.06686692]\n",
            " [0.28251142 0.0507485  0.05091322 0.56501403 0.05081283]\n",
            " ...\n",
            " [0.05105174 0.79669942 0.05060591 0.05105554 0.0505874 ]\n",
            " [0.06725224 0.06776525 0.50140452 0.06866788 0.29491012]\n",
            " [0.58919004 0.1024443  0.10288586 0.10111878 0.10436103]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs6EbnRQ0GOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bcb550-a3de-4d81-8062-7d72cb7ae29c"
      },
      "source": [
        "print(lda_model.components_)\n",
        "print(lda_model.components_.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 62.9613972  112.56515042 130.26183607 ... 270.18353991 143.05968891\n",
            "   48.25627233]\n",
            " [111.6665269  188.41125177  18.71313384 ...  70.83646701 445.57221993\n",
            "  217.48606112]\n",
            " [  3.63918254  86.36572944 192.43249871 ... 374.13835919 153.08214511\n",
            "   60.25153488]\n",
            " [  0.70170372  79.42634486 156.16915374 ... 236.55242643  36.41164784\n",
            "   92.95728671]\n",
            " [292.03118964 125.23152352 144.42337764 ... 173.28920746 117.87429821\n",
            "   36.04884496]]\n",
            "(5, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shhnkY-p-RhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fa599f-f978-4678-8225-d34f2395499c"
      },
      "source": [
        "vocab = model.get_feature_names()\n",
        "\n",
        "for i, comp in enumerate(lda_model.components_):\n",
        "    vocab_comp = zip(vocab, comp)\n",
        "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
        "    print(\"Topic \"+str(i)+\": \")\n",
        "    for t in sorted_words:\n",
        "        print(t[0],end=\" \")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0: \n",
            "police govt council say new plan crash man death nsw \n",
            "\n",
            "Topic 1: \n",
            "kill man govt charge qld open set accuse pm case \n",
            "\n",
            "Topic 2: \n",
            "plan govt urge win council police cou group continue charge \n",
            "\n",
            "Topic 3: \n",
            "new help miss water seek govt die consider man sydney \n",
            "\n",
            "Topic 4: \n",
            "hit man death year plan fund push drug new charge \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcpyDROJyL9r",
        "outputId": "66543db8-f919-47f6-9fcd-a42e061bb364"
      },
      "source": [
        "!pip install mglearn"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mglearn\n",
            "  Downloading mglearn-0.1.9.tar.gz (540 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 37.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 39.9 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 42.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 112 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 225 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 245 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 358 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 378 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 430 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 450 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 471 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 481 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 491 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 512 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 540 kB 30.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mglearn) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.1.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from mglearn) (7.1.2)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from mglearn) (2.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler->mglearn) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->mglearn) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mglearn) (1.4.1)\n",
            "Building wheels for collected packages: mglearn\n",
            "  Building wheel for mglearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582638 sha256=2381b927cd2f5fe9c88786e55339b0e1161933810f5a9845891566a54c28425a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/17/e1/1720d6dcd70187b6b6c3750cb3508798f2b1d57c9d3214b08b\n",
            "Successfully built mglearn\n",
            "Installing collected packages: mglearn\n",
            "Successfully installed mglearn-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_WPYFdKtm6c",
        "outputId": "9d3dfff8-9b70-453e-b977-4a4c075a3fe9"
      },
      "source": [
        "import mglearn as mg\n",
        "sorting = np.argsort(lda_model.components_)[:,::-1]\n",
        "features = np.array(model.get_feature_names())\n",
        "mg.tools.print_topics(topics=range(5),feature_names= features,sorting = sorting,topics_per_chunk = 5,n_words = 25)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
            "--------      --------      --------      --------      --------      \n",
            "police        kill          plan          new           hit           \n",
            "govt          man           govt          help          man           \n",
            "council       govt          urge          miss          death         \n",
            "say           charge        win           water         year          \n",
            "new           qld           council       seek          plan          \n",
            "plan          open          police        govt          fund          \n",
            "crash         set           cou           die           push          \n",
            "man           accuse        group         consider      drug          \n",
            "death         pm            continue      man           new           \n",
            "nsw           case          charge        sydney        charge        \n",
            "water         claim         farmer        home          rise          \n",
            "australia     face          qld           suppo         health        \n",
            "win           strike        face          iraq          national      \n",
            "attack        cou           say           union         test          \n",
            "final         house         cut           say           repo          \n",
            "urge          crash         concern       face          seek          \n",
            "election      police        mp            health        claim         \n",
            "inquiry       talk          school        wa            cou           \n",
            "study         close         reject        lose          woman         \n",
            "probe         aust          question      centre        road          \n",
            "change        boost         bid           jail          price         \n",
            "defend        assault       aid           car           begin         \n",
            "investigate   england       iraq          funding       kill          \n",
            "target        resident      murder        work          attack        \n",
            "deal          market        change        australian    expect        \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnNxGIGTtnQG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}